
lora r 8
Step	Training Loss	Validation Loss	Val-auc	Val-accuracy
10	0.515100	0.459036	0.500000	0.825927
20	0.469900	0.414067	0.500000	0.825927
30	0.384200	0.345644	0.500000	0.825927
40	0.303600	0.259535	0.649834	0.878091
50	0.206400	0.168237	0.914067	0.963679
60	0.152000	0.130496	0.928572	0.956530
70	0.092100	0.087865	0.938133	0.971600
80	0.117400	0.081266	0.950046	0.971020
90	0.069300	0.076134	0.956060	0.970827
100	0.040600	0.105056	0.961072	0.958849
110	0.068000	0.056051	0.963250	0.978362

lora_S r 8 only diagonal
Step	Training Loss	Validation Loss	Val-auc	Val-accuracy
10	0.503400	0.456457	0.500000	0.825927
20	0.462700	0.372990	0.500000	0.825927
30	0.336700	0.261596	0.701443	0.896059
40	0.212600	0.178427	0.909179	0.950541
50	0.124500	0.104507	0.925198	0.971213
60	0.115300	0.095840	0.940231	0.966383
70	0.062600	0.061059	0.953995	0.979714
80	0.088700	0.050777	0.960801	0.982998
90	0.052600	0.069449	0.969640	0.973725
100	0.033100	0.066974	0.971245	0.972759
110	0.050800	0.040209	0.973679	0.984737
120	0.043500	0.099574	0.964810	0.959235
130	0.030900	0.038792	0.975926	0.983385
140	0.028900	0.064009	0.972997	0.972759
150	0.051600	0.036450	0.979052	0.984930
160	0.034400	0.055330	0.975715	0.975077
170	0.030800	0.040217	0.978992	0.983385
180	0.028500	0.031401	0.979054	0.987828
190	0.007000	0.028265	0.980605	0.991113
200	0.050100	0.031840	0.980425	0.986476
210	0.022700	0.057975	0.977584	0.975270

pissa
Step	Training Loss	Validation Loss	Val-auc	Val-accuracy
10	0.511600	0.455298	0.500000	0.825927
20	0.463200	0.389234	0.500000	0.825927
30	0.356800	0.302096	0.613208	0.865340
40	0.251900	0.194254	0.872712	0.953246
50	0.157700	0.139929	0.926883	0.960974
60	0.130600	0.120337	0.938268	0.958076
70	0.079300	0.076697	0.952387	0.977782
80	0.119600	0.092119	0.952492	0.963485
90	0.060900	0.086617	0.956991	0.966577
100	0.043800	0.102041	0.955961	0.956917

lora r 32
Step	Training Loss	Validation Loss	Val-auc	Val-accuracy
10	0.516400	0.459589	0.500000	0.825927
20	0.470400	0.416498	0.500000	0.825927
30	0.387100	0.350945	0.500000	0.825927
40	0.312500	0.275155	0.609878	0.864181
50	0.224800	0.185006	0.911118	0.963872
60	0.161700	0.135438	0.928164	0.957303
70	0.095300	0.089107	0.938106	0.973725
80	0.128100	0.084787	0.948264	0.970247
90	0.074000	0.076939	0.957287	0.971406
100	0.042800	0.096809	0.962653	0.962906
110	0.067600	0.056466	0.964477	0.978941
120	0.066300	0.126671	0.954754	0.945518
130	0.048900	0.056944	0.967804	0.977202
140	0.045900	0.067669	0.969143	0.972179
150	0.038200	0.053663	0.969147	0.977975
160	0.055700	0.049480	0.969645	0.979521
170	0.034400	0.082923	0.966888	0.964838
180	0.041500	0.046745	0.970230	0.980487
190	0.017600	0.041941	0.971021	0.983964
200	0.066300	0.048624	0.972186	0.980100
210	0.033100	0.090566	0.965572	0.961940

lora r 64
Step	Training Loss	Validation Loss	Val-auc	Val-accuracy
10	0.516800	0.459762	0.500000	0.825927
20	0.470500	0.417315	0.500000	0.825927
30	0.388000	0.352679	0.500000	0.825927
40	0.315700	0.281107	0.590455	0.857419
50	0.234000	0.195543	0.909366	0.963872
60	0.169200	0.139543	0.925770	0.957689
70	0.099100	0.093545	0.935769	0.972759
80	0.134200	0.089039	0.948585	0.970054
90	0.075600	0.078447	0.955622	0.970827
100	0.041700	0.092079	0.962478	0.964065
110	0.065700	0.057932	0.963337	0.977782
120	0.068600	0.128578	0.954169	0.944552
130	0.048300	0.055639	0.967513	0.978168
140	0.043100	0.066444	0.970165	0.973145
150	0.036100	0.049239	0.968097	0.979134
160	0.051100	0.060622	0.972475	0.976236
170	0.036700	0.075055	0.969227	0.968702
180	0.042800	0.049088	0.971193	0.979907
190	0.020700	0.044135	0.972305	0.983192
200	0.067700	0.047886	0.972888	0.981260
210	0.035900	0.087421	0.965689	0.962133

lora_s r 32
Step	Training Loss	Validation Loss	Val-auc	Val-accuracy
10	0.506400	0.456269	0.500000	0.825927
20	0.466200	0.387986	0.500000	0.825927
30	0.354100	0.290865	0.633740	0.872488
40	0.236200	0.180135	0.914739	0.964065
50	0.135900	0.109468	0.926950	0.971213
60	0.114100	0.099313	0.941923	0.964838
70	0.067600	0.065975	0.955453	0.977782
80	0.092000	0.054365	0.963486	0.981646
90	0.055300	0.065206	0.970342	0.974884
100	0.032600	0.076372	0.968438	0.968122
110	0.048400	0.042382	0.973970	0.983771
120	0.042100	0.085108	0.967296	0.964065
130	0.031900	0.037879	0.975839	0.983964
140	0.036400	0.055243	0.975103	0.976236
150	0.039500	0.034731	0.977885	0.985896
160	0.044600	0.039701	0.977210	0.982612
170	0.023700	0.047031	0.976653	0.979521
180	0.025700	0.029225	0.978763	0.988794
190	0.009400	0.032544	0.980017	0.987249
200	0.042400	0.035063	0.979403	0.985510
210	0.014700	0.045444	0.978843	0.979521
220	0.056900	0.037875	0.982994	0.984930

adalora
Step	Training Loss	Validation Loss	Val-auc	Val-accuracy
10	1.707800	1.628858	0.500000	0.825927
20	1.620200	1.551529	0.500000	0.825927
30	1.504400	1.452084	0.500000	0.825927
40	1.402300	1.360220	0.500555	0.826121
50	1.317500	1.271056	0.662597	0.882535
60	1.240400	1.185742	0.830831	0.940495
70	1.127100	1.103058	0.816870	0.936244
80	1.105200	1.028212	0.898765	0.961553
90	1.006800	0.962774	0.917541	0.962906
100	0.894800	0.881728	0.912812	0.965224
110	0.851400	0.813071	0.916697	0.966577
120	0.793800	0.757288	0.929543	0.964645


slora ortoreg
Step	Training Loss	Validation Loss	Val-auc	Val-accuracy
10	0.738700	0.690714	0.500000	0.825927
20	0.696300	0.605873	0.500000	0.825927
30	0.569400	0.494355	0.703108	0.896638
40	0.444800	0.405479	0.909911	0.952473
50	0.353200	0.333212	0.925198	0.971213
60	0.343200	0.322131	0.940348	0.966577
70	0.289600	0.287292	0.953557	0.979714
80	0.314400	0.276249	0.960801	0.982998
90	0.277000	0.292755	0.969991	0.974304
100	0.260300	0.294610	0.969842	0.970440
110	0.279400	0.262348	0.974207	0.987056
120	0.268900	0.334755	0.961886	0.954405
130	0.253300	0.260528	0.976745	0.984737
140	0.250200	0.279504	0.974284	0.974884
150	0.252900	0.251278	0.980341	0.989954
160	0.267400	0.281638	0.975481	0.974691
170	0.252800	0.264244	0.978203	0.982805
180	0.252500	0.253547	0.977827	0.987249
190	0.227700	0.250065	0.979933	0.990726
200	0.271400	0.252676	0.979987	0.986476
210	0.242400	0.278656	0.976678	0.974498
220	0.272800	0.251996	0.981359	0.985124
230	0.261800	0.241961	0.982444	0.990533
240	0.248800	0.250767	0.982118	0.984930
250	0.229300	0.270956	0.981207	0.978362
260	0.239000	0.238666	0.983613	0.992465
270	0.278900	0.246937	0.984280	0.987056
280	0.247800	0.276508	0.981993	0.976043
290	0.244100	0.236394	0.987993	0.992465
300	0.248200	0.232325	0.987411	0.994397
310	0.243300	0.270918	0.984039	0.977975
320	0.261700	0.253928	0.987314	0.983385
330	0.244000	0.236287	0.990708	0.991886
340	0.244100	0.230622	0.990272	0.994784
350	0.231100	0.235877	0.991818	0.992272
360	0.227000	0.236105	0.991818	0.992272
370	0.261500	0.239414	0.991086	0.990340
380	0.234700	0.240998	0.990501	0.989374
390	0.232900	0.240998	0.990501	0.989374



qnli
slora
Step	Training Loss	Validation Loss	Val-auc	Val-accuracy
10	0.693400	0.692296	0.512760	0.517115
20	0.696800	0.692090	0.504339	0.509610
30	0.687700	0.687940	0.533785	0.529746
40	0.691600	0.683967	0.576169	0.578986
50	0.690100	0.679301	0.570531	0.567088
60	0.683800	0.667853	0.633298	0.631704
70	0.660800	0.651567	0.605791	0.602233
80	0.650700	0.610005	0.700722	0.700348
90	0.616100	0.581428	0.716478	0.716090
100	0.571600	0.548593	0.733393	0.733663
110	0.584000	0.558304	0.728229	0.727073
120	0.568000	0.523472	0.750440	0.750686
130	0.548000	0.522527	0.748390	0.749222
140	0.557200	0.510271	0.760005	0.759839
150	0.537700	0.510630	0.751480	0.752517
160	0.539400	0.498276	0.765984	0.766063
170	0.544100	0.492910	0.768397	0.768625
180	0.565000	0.488984	0.776574	0.776679
190	0.536600	0.487690	0.778143	0.777778
200	0.518300	0.493599	0.778818	0.778144
210	0.573700	0.496034	0.760568	0.762036
220	0.560700	0.499144	0.779531	0.778693
230	0.478200	0.473607	0.788934	0.788761
240	0.534600	0.522564	0.759581	0.758191
250	0.550200	0.488807	0.771002	0.772286
260	0.550100	0.488511	0.776623	0.775581
270	0.500400	0.464105	0.796499	0.796632
280	0.474700	0.509352	0.772431	0.771188
290	0.554900	0.455907	0.797550	0.797913
300	0.491000	0.457590	0.805084	0.804869
310	0.475200	0.453271	0.794337	0.794801
320	0.507100	0.454034	0.804403	0.804137
330	0.524300	0.448400	0.804091	0.803954
340	0.512800	0.494063	0.771668	0.770273
350	0.502800	0.452340	0.794197	0.794984
360	0.490800	0.456309	0.804967	0.804503
370	0.516500	0.445634	0.796828	0.797547
380	0.423000	0.462437	0.803125	0.802489
390	0.495200	0.438662	0.804114	0.804137
400	0.562400	0.451883	0.797280	0.798096
410	0.498400	0.467147	0.791402	0.790408
420	0.502500	0.440554	0.803836	0.804320
430	0.471100	0.436950	0.809800	0.809628
440	0.516200	0.434982	0.809350	0.809445
450	0.474500	0.436353	0.810280	0.810178
460	0.515700	0.433215	0.810044	0.809995
470	0.473300	0.456666	0.796056	0.794984
480	0.445200	0.432543	0.811569	0.811093
490	0.454800	0.452278	0.801882	0.801025
500	0.465000	0.426030	0.809364	0.809811
510	0.444700	0.460486	0.801059	0.800110
520	0.524900	0.422881	0.819819	0.819879
530	0.459200	0.450369	0.801083	0.800110
540	0.533300	0.422416	0.817370	0.817500
550	0.437500	0.446477	0.806732	0.805784
560	0.494300	0.420317	0.816927	0.816584
570	0.445800	0.417169	0.817977	0.817866
580	0.413200	0.417898	0.814171	0.814571
590	0.453800	0.507733	0.780058	0.778510
600	0.506800	0.416826	0.819929	0.819879
610	0.472000	0.435223	0.812917	0.812191
620	0.443700	0.436117	0.811688	0.810910
630	0.469800	0.447000	0.805198	0.804137
640	0.542900	0.409722	0.820291	0.820428
650	0.469300	0.421190	0.819585	0.818964
660	0.428000	0.411344	0.823006	0.822625
670	0.442600	0.406170	0.820783	0.820794
680	0.505100	0.403918	0.822161	0.822259
690	0.513700	0.436077	0.809709	0.808713
700	0.469300	0.407377	0.825504	0.825554
710	0.486700	0.404160	0.826000	0.825920
720	0.443900	0.415992	0.821916	0.821344
730	0.425900	0.441265	0.806501	0.805418
740	0.477800	0.409721	0.822030	0.821527
750	0.423700	0.413097	0.821743	0.821161
760	0.496300	0.413458	0.820471	0.819879
770	0.422400	0.438830	0.801084	0.799927
780	0.444700	0.410045	0.819750	0.819330
790	0.436900	0.410370	0.822734	0.822442
800	0.466000	0.447336	0.802993	0.801940
810	0.414100	0.416475	0.818565	0.818049
820	0.479400	0.420798	0.813779	0.813106
830	0.474800	0.423585	0.815030	0.814388
840	0.356500	0.407407	0.824607	0.824455
850	0.465700	0.411053	0.826548	0.826469
860	0.450400	0.407656	0.825306	0.825554
870	0.495000	0.454579	0.803607	0.802489
880	0.509600	0.420813	0.822766	0.822259
890	0.492300	0.420952	0.819088	0.819696
900	0.463500	0.425772	0.817987	0.817316
910	0.473500	0.407198	0.823918	0.823723
920	0.479700	0.418490	0.818885	0.818232
930	0.409200	0.403918	0.822329	0.822808
940	0.404800	0.410797	0.819238	0.818781
950	0.506100	0.403174	0.820379	0.820062
960	0.462100	0.400259	0.821721	0.821527
970	0.461000	0.406248	0.822876	0.822442
980	0.455800	0.403285	0.821796	0.822442
990	0.454000	0.414928	0.818180	0.817500
1000	0.423800	0.399718	0.824600	0.824272
1010	0.454100	0.393429	0.826830	0.827018
1020	0.450400	0.412963	0.818960	0.818232
1030	0.408700	0.398482	0.825013	0.824638
1040	0.438900	0.404062	0.822632	0.822076
1050	0.450200	0.404795	0.822278	0.821710
1060	0.444300	0.394376	0.826843	0.826652
1070	0.449300	0.393449	0.828674	0.828483
1080	0.470700	0.392005	0.830880	0.831228
1090	0.491200	0.418009	0.821150	0.820245
1100	0.440400	0.397112	0.826474	0.826103
1110	0.443200	0.391256	0.827048	0.826835
1120	0.431200	0.396997	0.825415	0.825005
1130	0.415000	0.408278	0.812291	0.813289
1140	0.474400	0.399511	0.824872	0.824455
1150	0.432200	0.388155	0.830082	0.830130
1160	0.421300	0.409792	0.823660	0.822991
1170	0.440400	0.388895	0.831476	0.831594
1180	0.430800	0.389239	0.828476	0.828483
1190	0.360600	0.394892	0.825446	0.825188
1200	0.411700	0.400019	0.826608	0.826286
1210	0.456900	0.394067	0.824682	0.824455
1220	0.466600	0.392977	0.826477	0.826286
1230	0.494900	0.401975	0.826616	0.826286
1240	0.458300	0.397111	0.826036	0.825920
1250	0.390900	0.389904	0.827954	0.827750
1260	0.456900	0.395674	0.828608	0.828116
1270	0.447200	0.386181	0.832916	0.833242
1280	0.464200	0.395656	0.830947	0.830496
1290	0.474300	0.393051	0.832562	0.832693
1300	0.415500	0.387793	0.832509	0.832144
1310	0.464700	0.390906	0.832648	0.832144
1320	0.402200	0.382431	0.831642	0.831594
1330	0.431200	0.384311	0.832272	0.832144
1340	0.434300	0.390922	0.828707	0.828299
1350	0.410500	0.387293	0.830994	0.830679
1360	0.498300	0.385888	0.832954	0.832693
1370	0.365300	0.401789	0.823413	0.822625
1380	0.449000	0.384111	0.832786	0.833059
1390	0.509400	0.432573	0.806860	0.805601
1400	0.363000	0.385074	0.832750	0.832327
1410	0.464700	0.379951	0.837693	0.837635
1420	0.429700	0.387661	0.832766	0.832327
1430	0.440500	0.392301	0.831786	0.831228
1440	0.413300	0.384553	0.834883	0.834523
1450	0.482900	0.379850	0.837272	0.837086
1460	0.408900	0.401709	0.824685	0.823906
1470	0.364300	0.379008	0.839418	0.839282
1480	0.450800	0.388989	0.833703	0.833242
1490	0.484300	0.377303	0.837318	0.837452
1500	0.425500	0.380002	0.838327	0.838184
1510	0.446700	0.381037	0.831628	0.831960
1520	0.446500	0.389381	0.834781	0.834340
1530	0.477200	0.384163	0.839320	0.839099
1540	0.404600	0.381147	0.837961	0.837818
1550	0.413900	0.376223	0.837775	0.838001
1560	0.431900	0.382773	0.834734	0.834340


lora 8
Step	Training Loss	Validation Loss	Val-auc	Val-accuracy
10	0.693500	0.692379	0.514019	0.518580
20	0.696900	0.692730	0.501512	0.506864
30	0.688300	0.688407	0.545369	0.542010
40	0.693500	0.686109	0.577565	0.578986
50	0.690900	0.685112	0.556916	0.553542
60	0.692000	0.682180	0.597821	0.597291
70	0.679700	0.682379	0.544298	0.539996
80	0.680900	0.674670	0.612881	0.613033
90	0.674900	0.668707	0.623543	0.624565
100	0.661300	0.657075	0.624325	0.622003
110	0.660900	0.640576	0.634350	0.631704
120	0.631800	0.612327	0.692133	0.692294
130	0.614800	0.588624	0.694668	0.695772
140	0.596200	0.576944	0.705354	0.704558
150	0.571500	0.575235	0.694307	0.696138
160	0.595600	0.548745	0.721750	0.722131
170	0.591500	0.540915	0.731478	0.732015
180	0.595500	0.536295	0.734773	0.735310
190	0.579500	0.528556	0.740364	0.740802
200	0.547200	0.540493	0.738674	0.737690
210	0.595600	0.528935	0.732120	0.733480
220	0.567700	0.527213	0.747779	0.747025
230	0.527100	0.511008	0.762240	0.762219
240	0.557300	0.518450	0.754854	0.753981
250	0.565300	0.509297	0.751491	0.752700
260	0.549900	0.501736	0.770200	0.769541
270	0.516800	0.492743	0.775785	0.775398
280	0.501600	0.506773	0.770473	0.769541
290	0.579000	0.482172	0.781316	0.781073
300	0.493400	0.489771	0.777586	0.776863
310	0.491800	0.475655	0.776813	0.777229
320	0.531300	0.472497	0.784649	0.784734
330	0.561800	0.481901	0.783739	0.783086
340	0.523300	0.503056	0.767301	0.766063
350	0.527800	0.468326	0.787090	0.787296
360	0.530400	0.467491	0.787646	0.787662
370	0.537900	0.484878	0.782409	0.781622
380	0.443100	0.462121	0.783994	0.784368
390	0.500600	0.474548	0.786483	0.785832
400	0.587300	0.468187	0.786065	0.786564
410	0.512100	0.469950	0.790881	0.790225
420	0.513100	0.464703	0.793872	0.793337
430	0.485000	0.456375	0.788620	0.789127
440	0.533000	0.462644	0.793982	0.793520
450	0.501200	0.452559	0.792070	0.792239
460	0.535300	0.455844	0.797898	0.797730
470	0.501900	0.482434	0.779773	0.778510
480	0.463100	0.455529	0.798290	0.797730
490	0.469900	0.460691	0.794255	0.793520
500	0.487900	0.444581	0.799433	0.799561
510	0.456100	0.479059	0.791579	0.790591
520	0.528800	0.443093	0.802261	0.801940
530	0.469000	0.465875	0.792339	0.791323
540	0.554000	0.446945	0.803474	0.803039
550	0.463200	0.448168	0.802534	0.801940
560	0.499200	0.446670	0.805282	0.804686
570	0.449200	0.435066	0.805512	0.805418
580	0.438500	0.438611	0.800478	0.801025
590	0.488400	0.485868	0.788497	0.787296
600	0.537300	0.446909	0.803495	0.802856
610	0.497900	0.440579	0.806077	0.805601
620	0.456400	0.477618	0.786380	0.785100
630	0.484500	0.451279	0.803240	0.802489
640	0.551400	0.429803	0.808429	0.808347
650	0.490300	0.437075	0.804644	0.804137
660	0.453800	0.437451	0.808558	0.807981
670	0.472300	0.425730	0.810027	0.810178
680	0.515200	0.426737	0.812240	0.812191
690	0.519600	0.446164	0.805511	0.804686
700	0.481500	0.428475	0.812894	0.812923
710	0.501800	0.427168	0.813123	0.812923
720	0.463300	0.431436	0.811360	0.810910
730	0.460600	0.457966	0.801367	0.800293
740	0.492000	0.460495	0.794887	0.793703
750	0.450400	0.427050	0.815647	0.815303
760	0.517800	0.445860	0.803260	0.802306
770	0.452500	0.451138	0.796627	0.795534
780	0.459200	0.427681	0.810683	0.810178
790	0.446700	0.420411	0.816874	0.816767
800	0.488900	0.490074	0.790604	0.789310
810	0.417300	0.446583	0.808590	0.807798
820	0.497500	0.423478	0.816919	0.816584
830	0.489900	0.443874	0.807559	0.806700
840	0.373500	0.428295	0.815167	0.814754
850	0.467600	0.419440	0.816058	0.816218
860	0.466800	0.424886	0.814958	0.814754
870	0.496300	0.451039	0.804729	0.803771
880	0.507400	0.440769	0.805708	0.804869
890	0.495700	0.426079	0.818172	0.818415
900	0.477200	0.432615	0.811861	0.811276
910	0.490000	0.428742	0.815238	0.814754
920	0.497000	0.434094	0.813727	0.813106
930	0.431600	0.417373	0.819046	0.819330
940	0.423900	0.428925	0.812810	0.812191
950	0.510700	0.427262	0.811727	0.811093
960	0.482000	0.419363	0.818045	0.817683
970	0.465500	0.423435	0.815073	0.814571
980	0.455500	0.412819	0.817066	0.817316
990	0.468500	0.421063	0.816120	0.815669
1000	0.431100	0.434691	0.808196	0.807432
1010	0.464600	0.409179	0.820449	0.820428
1020	0.461400	0.421340	0.814754	0.814205
1030	0.424600	0.430236	0.812956	0.812191
1040	0.457900	0.415096	0.817376	0.816950
1050	0.462700	0.430115	0.811712	0.810910
1060	0.453300	0.407116	0.820087	0.820062
1070	0.446100	0.407413	0.820651	0.820428
1080	0.482400	0.404633	0.823424	0.823723
1090	0.510400	0.417533	0.820101	0.819513
1100	0.455900	0.430968	0.811996	0.811093
1110	0.456300	0.404510	0.825917	0.825920
1120	0.451800	0.420578	0.817806	0.817133
1130	0.433500	0.404023	0.823845	0.824272
1140	0.463900	0.411050	0.820888	0.820428
1150	0.443300	0.411984	0.819305	0.818781
1160	0.426300	0.423721	0.815921	0.815120
1170	0.478700	0.404791	0.824147	0.823906
1180	0.423400	0.402949	0.827083	0.827018
1190	0.389400	0.405934	0.823950	0.823723
1200	0.428800	0.428107	0.812586	0.811825
1210	0.471800	0.413987	0.820561	0.820062
1220	0.477300	0.406001	0.825367	0.825188
1230	0.492800	0.419549	0.816416	0.815852
1240	0.457800	0.413993	0.821167	0.820794
1250	0.387900	0.409194	0.821167	0.820794
1260	0.465400	0.412545	0.820376	0.819879
1270	0.454300	0.398955	0.825322	0.825554
1280	0.494000	0.402093	0.826036	0.825920
1290	0.485200	0.406926	0.826209	0.826103
1300	0.436800	0.411946	0.822262	0.821710
1310	0.484100	0.405096	0.823395	0.822991
1320	0.416800	0.404906	0.825569	0.825188
1330	0.454200	0.397268	0.828079	0.828116
1340	0.437100	0.416425	0.819294	0.818598
1350	0.429200	0.405311	0.824344	0.823906
1360	0.515500	0.399231	0.827186	0.827018
1370	0.388000	0.416624	0.815929	0.815120
1380	0.453800	0.395828	0.826040	0.825920
1390	0.510800	0.435682	0.802037	0.800842
1400	0.383100	0.411452	0.818795	0.818049
1410	0.480500	0.398304	0.828041	0.827750
1420	0.434700	0.402038	0.825407	0.825005
1430	0.452500	0.412842	0.819543	0.818781
1440	0.436200	0.401655	0.823640	0.823174
1450	0.476000	0.398282	0.827175	0.826835
1460	0.414000	0.412289	0.821334	0.820611
1470	0.381900	0.398105	0.828029	0.827750
1480	0.450800	0.410714	0.821786	0.821161
1490	0.495600	0.392726	0.831099	0.831045
1500	0.430700	0.393873	0.829863	0.829764
1510	0.457500	0.393437	0.829063	0.829032
1520	0.462400	0.410423	0.818353	0.817683
1530	0.494200	0.398924	0.829655	0.829398
